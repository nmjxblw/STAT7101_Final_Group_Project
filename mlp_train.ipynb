{
 "cells": [
  {
   "cell_type": "code",
   "id": "1239a5f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T08:08:59.543694Z",
     "start_time": "2025-11-17T08:08:44.795353Z"
    }
   },
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "38393096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T08:09:00.135408Z",
     "start_time": "2025-11-17T08:08:59.554599Z"
    }
   },
   "source": [
    "df = pd.read_csv(\"freq_features_data.csv\")\n",
    "\n",
    "X = df.drop('inv_key', axis=1)\n",
    "y = df['inv_key']\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "6c0ac619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T08:09:00.514278Z",
     "start_time": "2025-11-17T08:09:00.144021Z"
    }
   },
   "source": [
    "char2idx = {chr(ord('a') + i): i for i in range(26)}\n",
    "idx2char = {i: chr(ord('a') + i) for i in range(26)}\n",
    "letters = [i for i in 'abcdefghijklmnopqrstuvwxyz']\n",
    "\n",
    "def preprocess_X(X_train, X_val):\n",
    "    \"\"\"标准化输入特征（训练集拟合，验证集转换）\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    # 转换为PyTorch张量（float32）\n",
    "    return torch.tensor(X_train_scaled, dtype=torch.float32), torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "\n",
    "def preprocess_y(Y):\n",
    "    Y = [[i for i in list(y) if i in letters] for y in Y]\n",
    "    y_idx = np.array([[char2idx[c] for c in row] for row in Y])  # (样本数, 26)\n",
    "    return torch.tensor(y_idx, dtype=torch.long)  # 类索引（long类型）\n",
    "\n",
    "preprocess_y(y_train).shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12000, 26])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "0a9e7a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T08:09:00.556983Z",
     "start_time": "2025-11-17T08:09:00.522829Z"
    }
   },
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_DIM = 702  # 输入特征维度\n",
    "NUM_TASKS = 26  # 26个分类任务\n",
    "NUM_CLASSES_PER_TASK = 26  # 每个任务26个类别（a-z）\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-4\n",
    "EPOCHS = 80\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "# ---------------------- 3. 自定义数据集类 ----------------------\n",
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X  # (样本数, 702) 张量\n",
    "        self.y = y  # (样本数, 26) 张量（每个元素是0-25的类索引）\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]  # 返回单个样本（特征+26个任务的标签）\n",
    "\n",
    "# ---------------------- 4. MLP模型定义（共享特征+多任务输出） ----------------------\n",
    "class MultiTaskMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskMLP, self).__init__()\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(INPUT_DIM, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(512, HIDDEN_DIM),\n",
    "            nn.BatchNorm1d(HIDDEN_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(HIDDEN_DIM, HIDDEN_DIM),\n",
    "            nn.BatchNorm1d(HIDDEN_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(HIDDEN_DIM, HIDDEN_DIM),\n",
    "            nn.BatchNorm1d(HIDDEN_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "        self.task_heads = nn.ModuleList([\n",
    "            nn.Linear(HIDDEN_DIM, NUM_CLASSES_PER_TASK) for _ in range(NUM_TASKS)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播：输入→共享特征→26个任务输出\"\"\"\n",
    "        shared_features = self.shared_layers(x)\n",
    "        outputs = [head(shared_features) for head in self.task_heads]\n",
    "        return outputs\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    # 记录每个任务的总正确数和总样本数\n",
    "    task_correct = [0] * NUM_TASKS\n",
    "    task_total = [0] * NUM_TASKS\n",
    "    \n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)  # (batch_size, 26)\n",
    "        \n",
    "        # 前向传播：获取26个任务的输出（每个输出是(batch_size, 26)）\n",
    "        outputs = model(X_batch)\n",
    "        \n",
    "        # 计算每个任务的损失，求和作为总损失\n",
    "        loss = 0.0\n",
    "        for i in range(NUM_TASKS):\n",
    "            task_output = outputs[i]  # (batch_size, 26)\n",
    "            task_y = y_batch[:, i]    # (batch_size,) 第i个任务的标签\n",
    "            loss += criterion(task_output, task_y)\n",
    "        \n",
    "        # 反向传播与优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 累计损失\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "        # 计算每个任务的准确率\n",
    "        for i in range(NUM_TASKS):\n",
    "            task_output = outputs[i]\n",
    "            task_y = y_batch[:, i]\n",
    "            _, predicted = torch.max(task_output, 1)  # 预测类别索引\n",
    "            task_correct[i] += (predicted == task_y).sum().item()\n",
    "            task_total[i] += task_y.size(0)\n",
    "    \n",
    "    # 计算平均损失和每个任务的准确率\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    task_accs = [task_correct[i] / task_total[i] for i in range(NUM_TASKS)]\n",
    "    return avg_loss, task_accs\n",
    "\n",
    "def val_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    task_correct = [0] * NUM_TASKS\n",
    "    task_total = [0] * NUM_TASKS\n",
    "    \n",
    "    with torch.no_grad():  # 验证时不计算梯度\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            outputs = model(X_batch)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = 0.0\n",
    "            for i in range(NUM_TASKS):\n",
    "                task_output = outputs[i]\n",
    "                task_y = y_batch[:, i]\n",
    "                loss += criterion(task_output, task_y)\n",
    "            total_loss += loss.item() * X_batch.size(0)\n",
    "            \n",
    "            # 计算准确率\n",
    "            for i in range(NUM_TASKS):\n",
    "                task_output = outputs[i]\n",
    "                task_y = y_batch[:, i]\n",
    "                _, predicted = torch.max(task_output, 1)\n",
    "                task_correct[i] += (predicted == task_y).sum().item()\n",
    "                task_total[i] += task_y.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    task_accs = [task_correct[i] / task_total[i] for i in range(NUM_TASKS)]\n",
    "    return avg_loss, task_accs\n",
    "\n",
    "def predict(model, X_val, device):\n",
    "    model.eval()\n",
    "    X_val = X_val.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val)  # 26个任务的输出，每个(batch_size, 26)\n",
    "    \n",
    "    # 概率→类别索引→字符\n",
    "    y_pred = []\n",
    "    for sample_idx in range(len(X_val)):\n",
    "        sample_chars = []\n",
    "        for task_idx in range(NUM_TASKS):\n",
    "            task_output = outputs[task_idx][sample_idx]  # (26,)\n",
    "            pred_idx = torch.argmax(task_output).item()  # 预测索引\n",
    "            sample_chars.append(idx2char[pred_idx])      # 转换为字符\n",
    "        y_pred.append(sample_chars)\n",
    "    \n",
    "    return y_pred  # 形状：(样本数, 26)，与原始y格式一致"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "501c56ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T08:14:54.120939Z",
     "start_time": "2025-11-17T08:09:00.564743Z"
    }
   },
   "source": [
    "np.random.seed(42)\n",
    "X_train_tensor, X_val_tensor = preprocess_X(X_train, X_val)\n",
    "y_train_tensor = preprocess_y(y_train)\n",
    "y_val_tensor = preprocess_y(y_val)\n",
    "\n",
    "train_dataset = MultiTaskDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = MultiTaskDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ---------------------- 初始化模型、损失函数、优化器 ----------------------\n",
    "model = MultiTaskMLP().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()#label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "# ---------------------- 模型训练 ----------------------\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(EPOCHS):\n",
    "    # 训练一个epoch\n",
    "    train_loss, train_accs = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "    # 验证一个epoch\n",
    "    val_loss, val_accs = val_epoch(model, val_loader, criterion, DEVICE)\n",
    "    \n",
    "    # 学习率衰减（根据验证损失）\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # 计算平均准确率（所有任务的均值）\n",
    "    avg_train_acc = np.mean(train_accs)\n",
    "    avg_val_acc = np.mean(val_accs)\n",
    "    \n",
    "    # 打印日志\n",
    "    if epoch%4 == 0 or epoch == EPOCHS-1:\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Avg Train Acc: {avg_train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Avg Val Acc: {avg_val_acc:.4f}\")\n",
    "        print(f\"Task Accs (0-25): {[f'{acc:.4f}' for acc in val_accs[:5]]}...\")  # 打印前5个任务的准确率\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if avg_val_acc > best_val_acc:\n",
    "        best_val_acc = avg_val_acc\n",
    "        torch.save(model.state_dict(), \"best_multi_task_mlp.pth\")\n",
    "        print(f\"Best model saved (Epoch: {epoch+1} | Val Acc: {best_val_acc:.4f})\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80]\n",
      "Train Loss: 83.5402 | Avg Train Acc: 0.0707\n",
      "Val Loss: 79.9627 | Avg Val Acc: 0.0980\n",
      "Task Accs (0-25): ['0.0797', '0.0947', '0.0970', '0.0943', '0.1057']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 1 | Val Acc: 0.0980)\n",
      "Best model saved (Epoch: 2 | Val Acc: 0.1209)\n",
      "Best model saved (Epoch: 3 | Val Acc: 0.1395)\n",
      "Best model saved (Epoch: 4 | Val Acc: 0.1561)\n",
      "Epoch [5/80]\n",
      "Train Loss: 68.1812 | Avg Train Acc: 0.1757\n",
      "Val Loss: 67.0656 | Avg Val Acc: 0.1717\n",
      "Task Accs (0-25): ['0.1593', '0.1703', '0.1820', '0.1743', '0.1927']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 5 | Val Acc: 0.1717)\n",
      "Best model saved (Epoch: 6 | Val Acc: 0.1866)\n",
      "Best model saved (Epoch: 7 | Val Acc: 0.1954)\n",
      "Best model saved (Epoch: 8 | Val Acc: 0.2045)\n",
      "Epoch [9/80]\n",
      "Train Loss: 61.9764 | Avg Train Acc: 0.2226\n",
      "Val Loss: 60.7244 | Avg Val Acc: 0.2174\n",
      "Task Accs (0-25): ['0.2033', '0.2140', '0.2260', '0.2037', '0.2327']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 9 | Val Acc: 0.2174)\n",
      "Best model saved (Epoch: 10 | Val Acc: 0.2219)\n",
      "Best model saved (Epoch: 11 | Val Acc: 0.2270)\n",
      "Best model saved (Epoch: 12 | Val Acc: 0.2319)\n",
      "Epoch [13/80]\n",
      "Train Loss: 58.7063 | Avg Train Acc: 0.2494\n",
      "Val Loss: 57.5602 | Avg Val Acc: 0.2394\n",
      "Task Accs (0-25): ['0.2263', '0.2330', '0.2430', '0.2363', '0.2493']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 13 | Val Acc: 0.2394)\n",
      "Best model saved (Epoch: 14 | Val Acc: 0.2425)\n",
      "Best model saved (Epoch: 15 | Val Acc: 0.2482)\n",
      "Best model saved (Epoch: 16 | Val Acc: 0.2529)\n",
      "Epoch [17/80]\n",
      "Train Loss: 56.7003 | Avg Train Acc: 0.2700\n",
      "Val Loss: 55.5120 | Avg Val Acc: 0.2562\n",
      "Task Accs (0-25): ['0.2407', '0.2530', '0.2587', '0.2463', '0.2697']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 17 | Val Acc: 0.2562)\n",
      "Best model saved (Epoch: 18 | Val Acc: 0.2594)\n",
      "Best model saved (Epoch: 19 | Val Acc: 0.2613)\n",
      "Best model saved (Epoch: 20 | Val Acc: 0.2674)\n",
      "Epoch [21/80]\n",
      "Train Loss: 55.3071 | Avg Train Acc: 0.2840\n",
      "Val Loss: 54.1056 | Avg Val Acc: 0.2672\n",
      "Task Accs (0-25): ['0.2457', '0.2500', '0.2950', '0.2447', '0.2933']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 22 | Val Acc: 0.2708)\n",
      "Best model saved (Epoch: 23 | Val Acc: 0.2732)\n",
      "Best model saved (Epoch: 24 | Val Acc: 0.2766)\n",
      "Epoch [25/80]\n",
      "Train Loss: 54.1769 | Avg Train Acc: 0.2975\n",
      "Val Loss: 52.9662 | Avg Val Acc: 0.2805\n",
      "Task Accs (0-25): ['0.2663', '0.2560', '0.3033', '0.2693', '0.2897']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 25 | Val Acc: 0.2805)\n",
      "Best model saved (Epoch: 26 | Val Acc: 0.2822)\n",
      "Best model saved (Epoch: 27 | Val Acc: 0.2829)\n",
      "Best model saved (Epoch: 28 | Val Acc: 0.2868)\n",
      "Epoch [29/80]\n",
      "Train Loss: 53.3233 | Avg Train Acc: 0.3069\n",
      "Val Loss: 52.1440 | Avg Val Acc: 0.2880\n",
      "Task Accs (0-25): ['0.2807', '0.2647', '0.3217', '0.2680', '0.2960']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 29 | Val Acc: 0.2880)\n",
      "Best model saved (Epoch: 30 | Val Acc: 0.2917)\n",
      "Best model saved (Epoch: 31 | Val Acc: 0.2931)\n",
      "Best model saved (Epoch: 32 | Val Acc: 0.2936)\n",
      "Epoch [33/80]\n",
      "Train Loss: 52.5886 | Avg Train Acc: 0.3160\n",
      "Val Loss: 51.3395 | Avg Val Acc: 0.2952\n",
      "Task Accs (0-25): ['0.2663', '0.2767', '0.3147', '0.2740', '0.3123']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 33 | Val Acc: 0.2952)\n",
      "Best model saved (Epoch: 34 | Val Acc: 0.2985)\n",
      "Best model saved (Epoch: 35 | Val Acc: 0.3000)\n",
      "Best model saved (Epoch: 36 | Val Acc: 0.3017)\n",
      "Epoch [37/80]\n",
      "Train Loss: 51.9427 | Avg Train Acc: 0.3221\n",
      "Val Loss: 50.6972 | Avg Val Acc: 0.3029\n",
      "Task Accs (0-25): ['0.2920', '0.2860', '0.3337', '0.2733', '0.3167']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 37 | Val Acc: 0.3029)\n",
      "Best model saved (Epoch: 38 | Val Acc: 0.3059)\n",
      "Best model saved (Epoch: 39 | Val Acc: 0.3061)\n",
      "Best model saved (Epoch: 40 | Val Acc: 0.3087)\n",
      "Epoch [41/80]\n",
      "Train Loss: 51.2836 | Avg Train Acc: 0.3300\n",
      "Val Loss: 50.1050 | Avg Val Acc: 0.3093\n",
      "Task Accs (0-25): ['0.3077', '0.2753', '0.3293', '0.2880', '0.3267']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 41 | Val Acc: 0.3093)\n",
      "Best model saved (Epoch: 42 | Val Acc: 0.3130)\n",
      "Best model saved (Epoch: 43 | Val Acc: 0.3139)\n",
      "Best model saved (Epoch: 44 | Val Acc: 0.3158)\n",
      "Epoch [45/80]\n",
      "Train Loss: 50.8501 | Avg Train Acc: 0.3360\n",
      "Val Loss: 49.4777 | Avg Val Acc: 0.3173\n",
      "Task Accs (0-25): ['0.3067', '0.2967', '0.3397', '0.2827', '0.3237']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 45 | Val Acc: 0.3173)\n",
      "Best model saved (Epoch: 46 | Val Acc: 0.3211)\n",
      "Best model saved (Epoch: 47 | Val Acc: 0.3219)\n",
      "Epoch [49/80]\n",
      "Train Loss: 50.4432 | Avg Train Acc: 0.3404\n",
      "Val Loss: 49.0150 | Avg Val Acc: 0.3228\n",
      "Task Accs (0-25): ['0.3140', '0.2953', '0.3537', '0.3003', '0.3400']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 49 | Val Acc: 0.3228)\n",
      "Best model saved (Epoch: 50 | Val Acc: 0.3250)\n",
      "Best model saved (Epoch: 52 | Val Acc: 0.3275)\n",
      "Epoch [53/80]\n",
      "Train Loss: 49.9644 | Avg Train Acc: 0.3451\n",
      "Val Loss: 48.5929 | Avg Val Acc: 0.3285\n",
      "Task Accs (0-25): ['0.3100', '0.3083', '0.3600', '0.3107', '0.3430']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 53 | Val Acc: 0.3285)\n",
      "Best model saved (Epoch: 54 | Val Acc: 0.3298)\n",
      "Best model saved (Epoch: 55 | Val Acc: 0.3322)\n",
      "Best model saved (Epoch: 56 | Val Acc: 0.3328)\n",
      "Epoch [57/80]\n",
      "Train Loss: 49.5456 | Avg Train Acc: 0.3510\n",
      "Val Loss: 48.1574 | Avg Val Acc: 0.3325\n",
      "Task Accs (0-25): ['0.3243', '0.3080', '0.3593', '0.3093', '0.3537']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 58 | Val Acc: 0.3346)\n",
      "Best model saved (Epoch: 59 | Val Acc: 0.3371)\n",
      "Epoch [61/80]\n",
      "Train Loss: 49.2852 | Avg Train Acc: 0.3545\n",
      "Val Loss: 47.7947 | Avg Val Acc: 0.3379\n",
      "Task Accs (0-25): ['0.3210', '0.3230', '0.3627', '0.3137', '0.3470']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 61 | Val Acc: 0.3379)\n",
      "Best model saved (Epoch: 62 | Val Acc: 0.3400)\n",
      "Best model saved (Epoch: 63 | Val Acc: 0.3425)\n",
      "Epoch [65/80]\n",
      "Train Loss: 48.8812 | Avg Train Acc: 0.3591\n",
      "Val Loss: 47.3697 | Avg Val Acc: 0.3442\n",
      "Task Accs (0-25): ['0.3183', '0.3197', '0.3623', '0.3177', '0.3577']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 65 | Val Acc: 0.3442)\n",
      "Best model saved (Epoch: 68 | Val Acc: 0.3450)\n",
      "Epoch [69/80]\n",
      "Train Loss: 48.7009 | Avg Train Acc: 0.3614\n",
      "Val Loss: 47.0566 | Avg Val Acc: 0.3480\n",
      "Task Accs (0-25): ['0.3203', '0.3253', '0.3637', '0.3257', '0.3640']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 69 | Val Acc: 0.3480)\n",
      "Best model saved (Epoch: 70 | Val Acc: 0.3498)\n",
      "Epoch [73/80]\n",
      "Train Loss: 48.2433 | Avg Train Acc: 0.3657\n",
      "Val Loss: 46.6753 | Avg Val Acc: 0.3501\n",
      "Task Accs (0-25): ['0.3343', '0.3300', '0.3653', '0.3233', '0.3697']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 73 | Val Acc: 0.3501)\n",
      "Best model saved (Epoch: 74 | Val Acc: 0.3523)\n",
      "Best model saved (Epoch: 75 | Val Acc: 0.3534)\n",
      "Epoch [77/80]\n",
      "Train Loss: 48.0536 | Avg Train Acc: 0.3695\n",
      "Val Loss: 46.4901 | Avg Val Acc: 0.3541\n",
      "Task Accs (0-25): ['0.3310', '0.3497', '0.3780', '0.3377', '0.3713']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 77 | Val Acc: 0.3541)\n",
      "Best model saved (Epoch: 78 | Val Acc: 0.3542)\n",
      "Best model saved (Epoch: 79 | Val Acc: 0.3576)\n",
      "Epoch [80/80]\n",
      "Train Loss: 47.8420 | Avg Train Acc: 0.3711\n",
      "Val Loss: 46.1527 | Avg Val Acc: 0.3579\n",
      "Task Accs (0-25): ['0.3407', '0.3483', '0.3663', '0.3350', '0.3700']...\n",
      "--------------------------------------------------------------------------------\n",
      "Best model saved (Epoch: 80 | Val Acc: 0.3579)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7d5ee110",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T08:14:57.873917Z",
     "start_time": "2025-11-17T08:14:54.219965Z"
    }
   },
   "source": [
    "# ---------------------- 模型预测 ----------------------\n",
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load(\"best_multi_task_mlp.pth\"))\n",
    "# 对验证集预测\n",
    "y_pred = predict(model, X_val_tensor, DEVICE)\n",
    "\n",
    "# 打印预测结果示例（前3个样本）\n",
    "print(\"\\nValidation samples:\")\n",
    "for i in range(3):\n",
    "    print(f\"True key: {' '.join( [i for i in list(y_val.iloc[i]) if i in letters] )}\")\n",
    "    print(f\"Pred key: {' '.join(y_pred[i])}\")\n",
    "    print(\"-\" * 65)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation samples:\n",
      "True key: l j v f n a s h w z k b d o g c u p q x m t e i y r\n",
      "Pred key: l x b f n i t c z j y v y o g d u p j w l t e i y n\n",
      "-----------------------------------------------------------------\n",
      "True key: n s w x k g r e j l f b p z y u d c t v h o q m a i\n",
      "Pred key: s s k b q b c e q m f v y x b u l p s v o o w m e i\n",
      "-----------------------------------------------------------------\n",
      "True key: l n u z e v o p q b f d s m r j k h g y w i c t a x\n",
      "Pred key: m t u z e j o y q g f m t y r v v c g d w a n t a q\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "712693ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T08:14:57.907782Z",
     "start_time": "2025-11-17T08:14:57.906094Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
